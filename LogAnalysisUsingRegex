#!/usr/bin/env python3
import re
import csv
import sys
import operator
from pathlib import Path
from _collections import defaultdict
from _collections import OrderedDict


def parselog(logfile):
    # we need: The ranking of errors generated by the system (sorted by count)
    # we need: The usage statistics for the service. (sorted by count per error, info, type)
    # error_messages dict to count per-error, then two dicts for per user statistics
    error_messages = {}
    per_user = {}
    with open(logfile, "r") as f:
        for line in f:
            regex = r"([A-Z]{4,5}) ([\w ']*)\[?\#?([\d?]*)\]? \(([\w]*\.?[\w?]*)\)"
            matches = re.finditer(regex, line, re.MULTILINE)
            for match in matches:
                # This is messy and not hyper efficient, but works for what we are trying to do
                if match.group(4) not in per_user.keys():
                    per_user.setdefault(match.group(4), {})['ERROR'] = 0
                    per_user.setdefault(match.group(4), {})['INFO'] = 0

                if match.group(1) == "ERROR":
                    if match.group(2) in error_messages.keys():
                        error_messages[match.group(2)] += 1
                        per_user[match.group(4)]['ERROR'] += 1
                    else:
                        error_messages[match.group(2)] = 1
                        per_user[match.group(4)]['ERROR'] = 1
                if match.group(1) == "INFO":
                    per_user[match.group(4)]['INFO'] += 1

    sorted_error_messages = OrderedDict(sorted(error_messages.items(), key=operator.itemgetter(1), reverse=True))
    sorted_per_user = OrderedDict(sorted(per_user.items()))

    with open("/home/student-03-baa0b2ec8a94/error_message.csv", "w") as e:
        fieldnames = ['Error', 'Count']
        writer = csv.DictWriter(e, fieldnames=fieldnames)
        writer.writeheader()
        for error, count in sorted_error_messages.items():
            writer.writerow({'Error': error, 'Count': count})

    with open("/home/student-03-baa0b2ec8a94/user_statistics.csv", "w") as s:
        fieldnames = ['Username', 'INFO', 'ERROR']
        writer = csv.DictWriter(s, fieldnames=fieldnames)
        writer.writeheader()

        for key, val in sorted_per_user.items():
            row = {'Username': key}
            row.update(val)
            writer.writerow(row)


if __name__ == "__main__":
    parselog(sys.argv[1])
